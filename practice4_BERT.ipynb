{"cells":[{"cell_type":"markdown","source":["# **Practice: BERT** (Bidirectional Encoder Representations from Transformers)"],"metadata":{"id":"oGqBpUxK7dcQ"}},{"cell_type":"markdown","source":["Devlin, Jacob, et al.\"Bert: Pre-training of deep bidirectional transformers  for language understanding.\" [(paper link).](https://arxiv.org/abs/1810.04805)\n","\n"," BERT is one of the most famous pre-trained language models, released by Google in 2018. Using pre-trained BERT, we can solve many tasks, and this process is called `'fine-tuning'`. Fine-tuning is the process of training further on different tasks, readjusting the parameters of the pre-trained BERT.\n","\n","In this practice, we're going to focus on how to utilize BERT for the task we want to do. so we're going to load a pre-trained BERT model from huggingface and use it. Implementing the BERT model yourself is complicated, but it will help you a lot in understanding transformer in depth. If you're curious about the detailed code of the model, check out this [link](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py).\n","\n","Now, let's practice fine-tuning BERT to classify Naver movie reviews!\n","\n","**Note:** To ensure a smooth workflow, please run all the cells in sequential order. This way, dependencies and intermediate variables will correctly propagate from one cell to the next."],"metadata":{"id":"tnV7KnLX8Le5"}},{"cell_type":"markdown","source":["## Device\n","\n","You might need to use GPU for this Colab.\n","\n","Please click `Runtime` and then `'Change runtime type'`. Then set the `hardware accelerator` to GPU."],"metadata":{"id":"4h1Rv1BwCR36"}},{"cell_type":"markdown","source":["## Installation"],"metadata":{"id":"2s7QuOjPDCJm"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bQQKIJiRA5PN","outputId":"d7ea507e-aa9f-4705-ba13-e31acd28e938","executionInfo":{"status":"ok","timestamp":1733368831178,"user_tz":-540,"elapsed":29220,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}],"source":["# Get transformers made by HuggingFace\n","!pip install transformers\n","!pip install tensorflow\n","!pip install torch\n","!pip install pandas"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"9pdQyupfA8a1","executionInfo":{"status":"ok","timestamp":1733368853800,"user_tz":-540,"elapsed":22630,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[],"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime\n","\n","\n","#https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RVW1v1GEA8dP","outputId":"4c0e2ea1-76f6-4c46-f567-6112204a6eda","executionInfo":{"status":"ok","timestamp":1733368864449,"user_tz":-540,"elapsed":10678,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'nsmc'...\n","remote: Enumerating objects: 14763, done.\u001b[K\n","remote: Counting objects: 100% (14762/14762), done.\u001b[K\n","remote: Compressing objects: 100% (13012/13012), done.\u001b[K\n","remote: Total 14763 (delta 1748), reused 14762 (delta 1748), pack-reused 1 (from 1)\u001b[K\n","Receiving objects: 100% (14763/14763), 56.19 MiB | 13.77 MiB/s, done.\n","Resolving deltas: 100% (1748/1748), done.\n","Updating files: 100% (14737/14737), done.\n"]}],"source":["# Download Naver movie reviews and sentiment analysis data\n","!git clone https://github.com/e9t/nsmc.git"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuPQrCtcA8fY","outputId":"35e7e00e-b46a-42bc-bfec-14164aa23054","executionInfo":{"status":"ok","timestamp":1733368864751,"user_tz":-540,"elapsed":327,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["total 38640\n","drwxr-xr-x 5 root root     4096 Dec  5 03:21 .\n","drwxr-xr-x 1 root root     4096 Dec  5 03:20 ..\n","drwxr-xr-x 2 root root     4096 Dec  5 03:20 code\n","drwxr-xr-x 8 root root     4096 Dec  5 03:21 .git\n","-rw-r--r-- 1 root root  4893335 Dec  5 03:20 ratings_test.txt\n","-rw-r--r-- 1 root root 14628807 Dec  5 03:20 ratings_train.txt\n","-rw-r--r-- 1 root root 19515078 Dec  5 03:20 ratings.txt\n","drwxr-xr-x 2 root root   462848 Dec  5 03:21 raw\n","-rw-r--r-- 1 root root     2596 Dec  5 03:20 README.md\n","-rw-r--r-- 1 root root    36746 Dec  5 03:21 synopses.json\n"]}],"source":["# List files in a directory\n","!ls nsmc -la"]},{"cell_type":"markdown","source":["## Prepare Model's Input"],"metadata":{"id":"IZpVGmiqW5cb"}},{"cell_type":"markdown","source":["### Load Data\n","\n","In this section, we will examine the structure of the Naver movie reivew data.\n"],"metadata":{"id":"IA7CP9q9EN4I"}},{"cell_type":"markdown","source":["\n","### Question 1: What is the shape of data?"],"metadata":{"id":"MnwEIGYCY3M4"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rv0aGEOGA8hh","outputId":"9ac76958-5e7b-46b3-a7d9-12231db81914","executionInfo":{"status":"ok","timestamp":1733368865690,"user_tz":-540,"elapsed":946,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataset has 150000 rows and 3 columns\n","Test dataset has 50000 rows and 3 columns\n"]}],"source":["# Load training and test data by using Pandas\n","train = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\n","test = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')\n","\n","def get_shape(dataset):\n","  #TODO: Implement this function that takes a dataset object\n","  #and return the shape of dataset.\n","\n","  num_row = 0\n","  num_col = 0\n","\n","  ############ Your code here #############\n","  ## (~2 line of code)\n","  num_row = len(dataset)\n","  num_col = len(dataset.columns)\n","  #########################################\n","\n","  return num_row, num_col\n","\n","#Print shapes of train and test data\n","train_num_row, train_num_col = get_shape(train)\n","test_num_row, test_num_col = get_shape(test)\n","print(\"Train dataset has {} rows and {} columns\".format(train_num_row, train_num_col))\n","print(\"Test dataset has {} rows and {} columns\".format(test_num_row, test_num_col))"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"BcW7Vo3mA8mE","outputId":"7b0484d5-974e-4eb1-d336-7c23b7eed1dd","executionInfo":{"status":"ok","timestamp":1733368865692,"user_tz":-540,"elapsed":22,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n","5   5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0\n","6   7797314                              원작의 긴장감을 제대로 살려내지못했다.      0\n","7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0\n","8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n","9   5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1"],"text/html":["\n","  <div id=\"df-ab58bea2-aac9-4fed-8070-f76c70ddfd03\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5403919</td>\n","      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7797314</td>\n","      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>9443947</td>\n","      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7156791</td>\n","      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5912145</td>\n","      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab58bea2-aac9-4fed-8070-f76c70ddfd03')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ab58bea2-aac9-4fed-8070-f76c70ddfd03 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ab58bea2-aac9-4fed-8070-f76c70ddfd03');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e68748c0-49ad-453a-bd04-862ff3fd1b62\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e68748c0-49ad-453a-bd04-862ff3fd1b62')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e68748c0-49ad-453a-bd04-862ff3fd1b62 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train"}},"metadata":{},"execution_count":6}],"source":["# Print the first 10 lines of the training set\n","train.head(10)"]},{"cell_type":"markdown","source":["The Naver movie review dataset consists of three components: id, document, and label.\n","\n","*  \"id\" refers to the identifier of the review.\n","\n","*   \"document\" contains the text of the review.\n","*   \"label\" is used for sentiment categorization (0 or 1). A label \"0\" is likely to represent negative sentiment, and \"1\" is likely to represent positive sentiment.\n","\n","The dataset is a Python dictionary with keys \"id\", \"documents\", and \"labels\"."],"metadata":{"id":"-dpj5l9oeH4R"}},{"cell_type":"markdown","source":["### Preprocessing\n","\n","In this section, we will preprocess data to make input for BERT. BERT's input sentence should start with special token [CLS] and end with special token [SEP].\n","\n"," Extract the training review sentences and convert them into the input format for BERT.\n","\n","\n"],"metadata":{"id":"j4zdjIrAP5hD"}},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Qr1QwgKBOc2","outputId":"752b1ebe-bcbc-45bd-a406-affbc3e9f7d5","executionInfo":{"status":"ok","timestamp":1733368865692,"user_tz":-540,"elapsed":16,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["['아 더빙.. 진짜 짜증나네요 목소리' '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나'\n"," '너무재밓었다그래서보는것을추천한다' '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정'\n"," '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다']\n","[0 1 0 0 1]\n","['굳 ㅋ' 'GDNTOPCLASSINTHECLUB' '뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아'\n"," '지루하지는 않은데 완전 막장임... 돈주고 보기에는....'\n"," '3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??']\n","[1 0 0 0 0]\n","['[CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP]', '[CLS] 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나 [SEP]', '[CLS] 너무재밓었다그래서보는것을추천한다 [SEP]', '[CLS] 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정 [SEP]', '[CLS] 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다 [SEP]']\n","['[CLS] 굳 ㅋ [SEP]', '[CLS] GDNTOPCLASSINTHECLUB [SEP]', '[CLS] 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아 [SEP]', '[CLS] 지루하지는 않은데 완전 막장임... 돈주고 보기에는.... [SEP]', '[CLS] 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠?? [SEP]']\n"]}],"source":["# TODO:  Extract review sentences and labels from the training and test dataset\n","\n","############ Your code here #############\n","##(~4 line of code)\n","train_sentences = train['document'].values\n","train_labels = train['label'].values\n","test_sentences = test['document'].values\n","test_labels = test['label'].values\n","#########################################\n","\n","print(train_sentences[:5])\n","print(train_labels[:5])\n","print(test_sentences[:5])\n","print(test_labels[:5])\n","\n","#TODO: Convert the sentences into the input format for BERT (add the [CLS] and [SEP] tokens)\n","\n","############ Your code here #############\n","##(~2 line of code)\n","train_sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in train_sentences]\n","test_sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in test_sentences]\n","#########################################\n","\n","print(train_sentences[:5])\n","print(test_sentences[:5])\n"]},{"cell_type":"markdown","source":["### Tokenizing\n","\n","Tokenize preprocessed senctences using BERT tokenizer"],"metadata":{"id":"Jk24Q3x7aabj"}},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347,"referenced_widgets":["c9069aad6eb54f43aeeed6d0040bb8f5","1e870a2c4df84d46813430cb014891e9","64065a5bd3f94e46a79991b5bedb426c","1af5101bcf6042c39259a0388e81b24f","affb075472eb44049381f3f221f4a175","fd4cdb6dfec240ca8189880274f52b4d","bcc7e41231fd45d6a70d0e0ddba969d2","92756e4030de4b0d9cb365dd59e07575","00a61b407f9d45d68607f5fb474734b7","68f0bff360974fb5bdfa553327a09217","075268cc607b442c8b7bdde12e52dbcd","91616387856341d08ada440686fff37e","3e199b4de3c44ffc92e22dd46e4761a4","bc7fdc758e1147c8b60f236c1c7c77f2","dea19caf15dd4db6996d36213723992a","f9bba456faaa47819c44da2877b71e92","27aeb0482542480d8725955d79fdf37a","22c67af98b804f4ab880c37b1a919e01","d777e146e9b6451992b0368c64db8fc0","6b203a7d0e0d48e8b7eac902397f1d26","62e27ba037d842e8894c8838a775dad0","5768442df44941298a7e06ca655faf05","1138a5eb8a0449af9bed2c61d6c58f48","c5ea3b2c94fc438e854a66be26c7bc34","7999c51dc40d473fbb78f29ebf98bbb9","06461d4458e34fa5baf5199c1c9686a7","528631267e604db5a8f4c52c73bbffe0","a4023ac5dd6b4309a7eaa27b6f31ccfa","d91bbe7caa3f4749ae16b181e5e5662d","bc4cfb01a1de4200b7c9863deeab04b0","7052e10d26364d2abdd302036b574026","e780238408f8407aaae56fe960127c6d","631a8a948edf46029f928cb7e598a3f9","5c69e1b0b26546f08a97d11463c2698f","470d321d6ac944158603ada6ffda3adc","89369c3f5e424fb1b260cddd94dabfbe","fe42dda5bbd44dcc88d57504bd8a9f62","5485a7c014d049e983ef170e749e1412","6e06baee970941179a3d58d4cb0fc04b","c8130a9514664c73a9548c14bcd03097","0adb0c376b894520a6c88d89c02fd082","37daa805e6524e8d94a8f2b5892f108e","258bc4bddc564abbaaebb35d0ef6b643","0f9beabc6b52465ca31ef439ab2f9060"]},"id":"YL7HjeHABRg-","outputId":"eef4600a-66b5-4ea1-fbea-a36f521e9906","executionInfo":{"status":"ok","timestamp":1733368909108,"user_tz":-540,"elapsed":43428,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9069aad6eb54f43aeeed6d0040bb8f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91616387856341d08ada440686fff37e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1138a5eb8a0449af9bed2c61d6c58f48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c69e1b0b26546f08a97d11463c2698f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP]\n","['[CLS]', '아', '더', '##빙', '.', '.', '진', '##짜', '짜', '##증', '##나', '##네', '##요', '목', '##소', '##리', '[SEP]']\n","[CLS] 굳 ㅋ [SEP]\n","['[CLS]', '굳', '[UNK]', '[SEP]']\n"]}],"source":["# TODO\n","# 1. Load BERT tokenizer (use 'bert-base-multilingual-cased' model and set do_lower_case=False)\n","# Please refer to the tutorial below for Huggingface tokenizers:\n","# https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt\n","# 2. Tokenize the sentences by using the loaded BERT tokenizer\n","# 3. Put the tokenized sentences into a list.\n","\n","train_tokenized_texts = []\n","test_tokenized_texts = []\n","############ Your code here #############\n","##(~3 line of code)\n","bert_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","train_tokenized_texts = [bert_tokenizer.tokenize(sent) for sent in train_sentences]\n","test_tokenized_texts = [bert_tokenizer.tokenize(sent) for sent in test_sentences]\n","#########################################\n","\n","print (train_sentences[0])\n","print (train_tokenized_texts[0])\n","print (test_sentences[0])\n","print (test_tokenized_texts[0])"]},{"cell_type":"markdown","source":["### Padding\n","\n","In natural language processing, we convert a natural language sentence into a list of token ids. A natural language model processes a batch of multiple sentences in each iteration. But, sentences with variable lengths do not align each other, and thus they cannot be combined to a matrix. In such case, we pad the sentences such that  all the padded sentences have the same length, and then we combine these sentences as a matrix all at once.\n","\n","\n","\n","*   If sequence length is longer than the maximum length specified by a user, then truncate each sentence up to the maximum length.  \n","*   If sentence length is shorter than the maximum length, then put paddings at the end (\"post-padding\") to generate a new sequence with the maxtimum length. (Putting paddings at the beginning of a sentence is called \"pre-padding\".)\n","\n"],"metadata":{"id":"9KAYvd6saeqY"}},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fld8ofXoBRlc","outputId":"413192f9-a0c0-4d67-d160-256ee1e1f317","executionInfo":{"status":"ok","timestamp":1733368913570,"user_tz":-540,"elapsed":4467,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[   101   9519   9074 119005    119    119   9708 119235   9715 119230\n","  16439  77884  48549   9284  22333  12692    102      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0      0      0\n","      0      0      0      0      0      0      0      0]\n","[ 101 8911  100  102    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","    0    0]\n"]}],"source":["# Maximum length of the input sequence\n","MAX_LEN = 128\n","\n","\n","############ Your code here #############\n","# TODO\n","# 1. Convert the tokens into token ids,\n","# which are integer indices of tokens in their look-up table.\n","# Use 'tokenizer.convert_tokents_to_ids'\n","# (input: tokenized_texts, ouptut: intiger indices)\n","# 2. If |sequence| > MAX_LEN, truncate each sentence up to the MAX_LEN\n","# 3. If |sequence| < MAX_LEN, then put paddings at the end of the sentence\n","# Function 'pad_sequences(input, truncate, padding)' can be useful\n","# to genereate a new sequence with length of MAX_LEN\n","# Hint: Argument input takes integer indices. Set truncate=\"post\", padding=\"post\".\n","## (~4 line of code)\n","train_input_ids = [bert_tokenizer.convert_tokens_to_ids(x) for x in train_tokenized_texts]\n","test_input_ids = [bert_tokenizer.convert_tokens_to_ids(x) for x in test_tokenized_texts]\n","train_input_ids = pad_sequences(train_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","test_input_ids = pad_sequences(test_input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","#########################################\n","\n","\n","print(train_input_ids[0])\n","print(test_input_ids[0])"]},{"cell_type":"markdown","source":["### Attention Mask\n","\n","Attention Mask helps distinguish actual words from padding tokens during BERT's attention operations, ensuring that unnecessary attention is not directed towards padding tokens."],"metadata":{"id":"kdUIXQB_tieP"}},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bpZ5c4oBenq","outputId":"7a294445-8b3f-4ff2-b3e6-5e7983cb2bb3","executionInfo":{"status":"ok","timestamp":1733368924297,"user_tz":-540,"elapsed":10749,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"]}],"source":["# Initialize attention masks\n","train_attention_masks = []\n","test_attention_masks = []\n","#TODO: Set attention mask to 0 if a correponding position is a padding, 1 otherwise.\n","\n","############ Your code here #############\n","## (~6 lines of code)\n","train_attention_masks = [[float(i>0) for i in seq] for seq in train_input_ids]\n","test_attention_masks = [[float(i>0) for i in seq] for seq in test_input_ids]\n","\n","\n","\n","\n","########################################\n","\n","print(train_attention_masks[0])\n","print(test_attention_masks[0])"]},{"cell_type":"markdown","source":["### Data Split\n","\n","To prepare validation dataset, split training data into a training set and a validation set. Also, split attention masks into training masks and validation masks."],"metadata":{"id":"QOyFqMXNtvgB"}},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gTA4Tt07BeqR","outputId":"934599df-7a85-449c-ff8f-7e346fce3981","executionInfo":{"status":"ok","timestamp":1733368931526,"user_tz":-540,"elapsed":7262,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([   101,   9659, 118959,  11903,   8924,  78705,  11018,   9555,  11664,\n","           102,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0])\n","tensor(1)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n","tensor([  101,  9460, 11403, 11403, 19105, 10530, 25805, 30005, 77884, 29935,\n","          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0])\n","tensor(1)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n","tensor([ 101, 8911,  100,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0])\n","tensor(1)\n","tensor([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n"]}],"source":["# TODO\n","# 1. Split train data into training set and validation set.\n","# 2. Split attetion masks into training masks and validation masks.\n","# 3. Convert the output of Steps 1 and 2, test inputs, labels, and masks to pytorch tensors.\n","\n","############ Your code here #############\n","## (~11 lines of code)\n","## Note:\n","## Use sklearn's 'train_test_split()' function to split data and attention masks.\n","## To ensure consistency between data and attention masks, the random_state should be the same.\n","## (Also, using the same random_state helps maintain reproducibility in the data splitting process)\n","## Set test_size = 0.1\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n","    train_input_ids, train_labels, test_size=0.1, random_state=42\n",")\n","train_masks, validation_masks = train_test_split(\n","    train_attention_masks, test_size=0.1, random_state=42\n",")\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\n","test_inputs = torch.tensor(test_input_ids)\n","test_labels = torch.tensor(test_labels)\n","test_masks = torch.tensor(test_attention_masks)\n","########################################\n","\n","\n","print(train_inputs[0])\n","print(train_labels[0])\n","print(train_masks[0])\n","print(validation_inputs[0])\n","print(validation_labels[0])\n","print(validation_masks[0])\n","print(test_inputs[0])\n","print(test_labels[0])\n","print(test_masks[0])"]},{"cell_type":"markdown","source":["### Creating DataLoader, and Making Mini-Batch\n","\n","Now, we are going to create the final input for BERT. We need to combine multiple input tensors into a single tensor and retrieve the data using the batch size during training"],"metadata":{"id":"UfNZVN77LroM"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"lpDTP86uBe15","executionInfo":{"status":"ok","timestamp":1733368931526,"user_tz":-540,"elapsed":52,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[],"source":["# Set the batch size\n","batch_size = 100 # 32에서 100으로 수정\n","# TODO: Set the Pytorch DataLoader with input, attention masks, labels\n","\n","############ Your code here #############\n","## Note:\n","## 1. Create a TensorDataset object to combine train_inputs, train_masks and train_labels.\n","## Create a TensorDataset object to combine test_inputs, test_masks and test_labels.\n","## Create a TensorDataset object to combine validation_inputs, validation_masks and validation_labels.\n","## (using TensorDataset())\n","## 2. Create a RandomSampler object by using RandomSampler() for training and test sets.\n","## 3. Create a SequentialSampler object by using SequentialSampler() for validation set.\n","## 3. Create train dataloader, validation dataloader and test dataloader\n","## (use 'DataLoader()' and set its argument \"sampler\" to the samplers created above.)\n","## (~9 lines of code)\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n","########################################"]},{"cell_type":"markdown","source":["## GPU setup"],"metadata":{"id":"kaO-h21BV-lo"}},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vrTD2fzjB8_R","outputId":"65e64925-abe8-4320-b407-6e2ed7d7f12d","executionInfo":{"status":"ok","timestamp":1733368931858,"user_tz":-540,"elapsed":16,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}],"source":["# Get the device name\n","device_name = tf.test.gpu_device_name()\n","\n","# Inspect if the device is GPU\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"yf-qu5uxB_PQ","executionInfo":{"status":"ok","timestamp":1733368931858,"user_tz":-540,"elapsed":11,"user":{"displayName":"정인아","userId":"17927010373770908168"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0961817d-c531-4eef-9749-f9ec6333242c"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}],"source":["# Set the device\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"]},{"cell_type":"markdown","source":["## Create Model"],"metadata":{"id":"Vk-xJ-HKWBkY"}},{"cell_type":"code","execution_count":15,"metadata":{"id":"aZClRKUYB-SI","executionInfo":{"status":"ok","timestamp":1733368938463,"user_tz":-540,"elapsed":6611,"user":{"displayName":"정인아","userId":"17927010373770908168"}},"colab":{"base_uri":"https://localhost:8080/","height":926,"referenced_widgets":["91062fc14275403d9a9fd77afc6ba66a","dc15dfffe6834685a5e92f07aa0903b9","0ec0e9b5a0c2420ca28a94c86cdfc212","60b05545947e4a92bf5d9c8700d495ac","2d16317d67d742078f6498821c6be6b7","9db79d992e2a4714a009677c04a8f3f0","44c6813f75a5494d9c98de6ceffffaf5","902575c3fe1f48d7b85588765549cff2","69244a61746340ef86b31e07c77beeab","bc937bac0ce14519b870e3b978d3a563","3ee099c893d9445192f0281fef519170"]},"outputId":"77fdd856-5af1-4401-af42-8a127a4407e4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91062fc14275403d9a9fd77afc6ba66a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":15}],"source":["# Create a BERT model for classification\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n","model.cuda()"]},{"cell_type":"markdown","source":["## Optimizer & scheduler"],"metadata":{"id":"XALQ_DfgZAuV"}},{"cell_type":"markdown","source":["### Question 2: What is the number of total steps for training?\n","\n","---\n","\n"],"metadata":{"id":"o9raH1UhX83A"}},{"cell_type":"markdown","source":["The number of total steps = (the number of batches) $\\times$ (the number of epochs)\n"],"metadata":{"id":"k0zuIBbQCO7M"}},{"cell_type":"code","execution_count":16,"metadata":{"id":"XAB2n0lmCJsV","executionInfo":{"status":"ok","timestamp":1733368938464,"user_tz":-540,"elapsed":35,"user":{"displayName":"정인아","userId":"17927010373770908168"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5771c98b-3673-4768-e961-dbec4089712e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2700\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# Set an optimizer\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률\n","                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                )\n","\n","# Set the number of epochs\n","epochs = 2 # 원래 4인데, 오래 걸려서 2로 수정해서 돌리기\n","\n","############ Your code here #############\n","## Note:\n","## (~ 1 line of code)\n","## Total steps = the number of batches in a dataset * number of epochs\n","total_steps = len(train_dataloader) * epochs\n","#########################################\n","print(total_steps)\n","\n","# Create a scheduler that adjusts a learning rate at the begining\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"]},{"cell_type":"markdown","source":["## Metric: Accuracy\n","\n","Accuracy is a commonly-used metric to evaluate the performance of a classification model. Accuracy measures how many of the predictions made by the model are correct compared to the total number of predictions."],"metadata":{"id":"fwr1VbhYnWMC"}},{"cell_type":"code","execution_count":17,"metadata":{"id":"-WIx9VZgCJuw","executionInfo":{"status":"ok","timestamp":1733368938465,"user_tz":-540,"elapsed":34,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[],"source":["# TODO: Define function that computes an accuracy\n","# Accuracy = (Number of Correct Predictions) / (Total Number of Predictions)\n","# preds, labels: [batch size, number of classes (i.e., 2)]\n","def flat_accuracy(preds, labels):\n","############ Your code here #############\n","##(~ 3 lines of code)\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    accuracy = np.sum(pred_flat == labels_flat) / len(labels_flat)\n","#########################################\n","    return accuracy"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"q32Cw6V_CJwz","executionInfo":{"status":"ok","timestamp":1733368938465,"user_tz":-540,"elapsed":33,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[],"source":["# Function that shows time\n","def format_time(elapsed):\n","\n","    # Round\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # Convert into the format hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"]},{"cell_type":"markdown","source":["## Training\n","Now, we're going to train the model. An epoch loop consists of training and validation processes. With PyTorch, you can simply implement forward and backward operations. Now, let's fill in the code below!"],"metadata":{"id":"pGES-lrTZ1Vf"}},{"cell_type":"markdown","source":["### Question 3: What is the average of training loss for each epoch?"],"metadata":{"id":"UydK3zP_kwKS"}},{"cell_type":"code","execution_count":19,"metadata":{"id":"5yFZtmTeCJy_","executionInfo":{"status":"ok","timestamp":1733374048620,"user_tz":-540,"elapsed":5110185,"user":{"displayName":"정인아","userId":"17927010373770908168"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"66c1c430-70f5-43cd-fce6-765954fa66df"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 2 ========\n","Training...\n","  Batch   500  of  1,350.    Elapsed: 0:15:07.\n","  Batch 1,000  of  1,350.    Elapsed: 0:30:19.\n","\n","  Average training loss: 0.39\n","  Training epcoh took: 0:40:57\n","\n","Running Validation...\n","  Accuracy: 0.85\n","  Validation took: 0:01:36\n","\n","======== Epoch 2 / 2 ========\n","Training...\n","  Batch   500  of  1,350.    Elapsed: 0:15:11.\n","  Batch 1,000  of  1,350.    Elapsed: 0:30:23.\n","\n","  Average training loss: 0.29\n","  Training epcoh took: 0:41:01\n","\n","Running Validation...\n","  Accuracy: 0.86\n","  Validation took: 0:01:36\n","\n","Training complete!\n"]}],"source":["# Fix a random seed for reproducibility\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Initialize gradient\n","model.zero_grad()\n","\n","# Repeat for the number of epochs\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Set the start time\n","    t0 = time.time()\n","\n","    # Initialize loss\n","    total_loss = 0\n","\n","    # Set the model to train mode\n","    model.train()\n","\n","    # For each batch retrieved from a data loader\n","    for step, batch in enumerate(train_dataloader):\n","        # Show the information of every 500 iterations\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Move a current batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        ## Note: (~ 10 lines of code)\n","        ## 1. Extract data(input ids, mask, labels) from the batch.\n","        ## 2. Forward propagation. Give the model input consisting of ids, mask and labels.\n","        ## 3. Get loss. The model's outputs contain the loss,\n","        ##    so you don't need to calculate the loss again.\n","        ##    Just simply get the loss from the output.\n","        ## 4. Compute the total loss\n","        ## 5. Do back-propagation, i.e., loss.backward()\n","        ## 6. Gradient clipping. Use torch.nn.utils.clip_grad_norm_(), set max_norm=1.0\n","        ## 7. Update parameters by using the gradients, i.e., optimizer.step()\n","        ## 8. Decrease the learning rate with scheduler, i.e., scheduler.step()\n","        ## 9. Initialize gradient\n","        ###############################################################\n","        input_ids, input_mask, labels = batch\n","        outputs = model(input_ids, token_type_ids=None, attention_mask=input_mask, labels=labels)\n","        loss = outputs[0]\n","        total_loss += loss.item()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        model.zero_grad()\n","\n","    ################ Your code here ################################\n","    ## 10. Compute the average loss for each epoch\n","    ##(~1 line of code)\n","    avg_train_loss = total_loss / len(train_dataloader)\n","    #########################################################\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    # Set the inital time\n","    t0 = time.time()\n","\n","    # Change model to eval mode\n","    model.eval()\n","\n","    # Initialize variables\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # For each batch retrieved from a data loader\n","    for batch in validation_dataloader:\n","        # Put the batch into GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        ########### Your code here ##############################\n","        ## Note: (~9 lines of code)\n","        ## 1. Extract data(input ids, mask, labels) from the batch\n","        ## 2. In validation step, you don't need to compute gradients.\n","        ##    Wrap the forward operation with the 'with torch.no_grad():' statement.\n","        ## 3. Get \"logits\"\n","        ## 4. Move logits and labels to CPU. (use '.cpu()' or '.to('cpu')')\n","        ## 5. Compute accuracy by using output logits and labels\n","        ## (use flat_accuracy function that we defined before.)\n","        # Unpack the batch\n","        input_ids, input_mask, labels = batch\n","        with torch.no_grad():\n","            outputs = model(input_ids, token_type_ids=None, attention_mask=input_mask)\n","            logits = outputs.logits\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = labels.to('cpu').numpy()\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","    ##########################################################\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"]},{"cell_type":"markdown","source":["## Model Evaluation"],"metadata":{"id":"ClhFWIUxlK0w"}},{"cell_type":"markdown","source":["### Question 4: What is the test accuracy of our model?"],"metadata":{"id":"A8V9YnmElPjr"}},{"cell_type":"code","execution_count":20,"metadata":{"id":"Gu7vsdjoCJ1e","executionInfo":{"status":"ok","timestamp":1733374368403,"user_tz":-540,"elapsed":319820,"user":{"displayName":"정인아","userId":"17927010373770908168"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"81d5c76d-b712-4de8-cfdf-661c2575786c"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Batch   100  of    500.    Elapsed: 0:01:04.\n","  Batch   200  of    500.    Elapsed: 0:02:08.\n","  Batch   300  of    500.    Elapsed: 0:03:12.\n","  Batch   400  of    500.    Elapsed: 0:04:16.\n","\n","Accuracy: 0.86\n","Test took: 0:05:20\n"]}],"source":["# Set initial time\n","t0 = time.time()\n","\n","# Change to evel mode\n","model.eval()\n","\n","# Initialize variables\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# For each batch from the data loader\n","for step, batch in enumerate(test_dataloader):\n","    # Show the information for every 500 iterations\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # Put the batch into GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    ############# Your code here ##############################\n","    ## Note: (~9 lines of code)\n","    ## 1. Extract data(input ids, mask, labels) from the batch\n","    ## 2. In evaluation step, you don't need to compute gradients.\n","    ##    Wrap the forward operation with the 'with torch.no_grad():' statement.\n","    ## 3. Get \"logits\"\n","    ## 4. Move logits and labels to CPU. (use '.cpu()' or '.to('cpu')')\n","    ## 5. Compute accuracy by using output logits and labels\n","    ## (use flat_accuracy function that we defined before.)\n","    input_ids, input_mask, labels = batch\n","    with torch.no_grad():\n","        outputs = model(input_ids, token_type_ids=None, attention_mask=input_mask)\n","        logits = outputs.logits\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = labels.to('cpu').numpy()\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","    ##########################################################\n","print(\"\")\n","print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"]},{"cell_type":"markdown","source":["## Can your model correctly categorize new reviews? Let's feed sentences to your model on your own!"],"metadata":{"id":"4-2S9AT5mEFf"}},{"cell_type":"code","execution_count":23,"metadata":{"id":"aKcAZRntCJ3K","executionInfo":{"status":"ok","timestamp":1733374606354,"user_tz":-540,"elapsed":428,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"outputs":[],"source":["#TODO:\n","# Make function to convert sentences into input data format.\n","# This function performs preprocessing, tokenization, and padding,\n","# and creates attention masks. (just the same as what we did earlier.)\n","# Set the maximum length = 128\n","\n","def convert_input_data(sentences):\n","    ######### Your code here ##################\n","    #(~9 lines of code)\n","    sentences = [\"[CLS] \" + str(sentences) + \" [SEP]\"]\n","    tokenized_texts = [bert_tokenizer.tokenize(sent) for sent in sentences]\n","    MAX_LEN = 128\n","    input_ids = [bert_tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","    attention_masks = []\n","    # attention mask 구하는 것만 스스로\n","    attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n","    #################################################\n","    # Convert data to pytorch tensors\n","    inputs = torch.tensor(input_ids)\n","    masks = torch.tensor(attention_masks)\n","\n","    return inputs, masks\n","\n","# Test sentences\n","def test_sentences(sentences):\n","\n","    # Change to eval mode\n","    model.eval()\n","\n","    # Convert sentences to the input of BERT\n","    inputs, masks = convert_input_data(sentences)\n","\n","    # Move data into GPU\n","    b_input_ids = inputs.to(device)\n","    b_input_mask = masks.to(device)\n","\n","    # No gradient computation\n","    with torch.no_grad():\n","        # Forward propagation\n","        outputs = model(b_input_ids,\n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask)\n","\n","    # Get loss\n","    logits = outputs[0]\n","\n","    # Move data to CPU\n","    logits = logits.detach().cpu().numpy()\n","\n","    return logits\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"FG03t8E9CJ5V","executionInfo":{"status":"ok","timestamp":1733374606745,"user_tz":-540,"elapsed":10,"user":{"displayName":"정인아","userId":"17927010373770908168"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aaca9446-8340-49f9-aeeb-e946a3bbd3e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[-0.6949342   0.38941282]]\n","1\n"]}],"source":["# Enter your review below to test your trained model\n","logits = test_sentences('Enter your review here')\n","\n","print(logits)\n","print(np.argmax(logits))"]},{"cell_type":"code","source":[],"metadata":{"id":"oVLzZUsEpyW7","executionInfo":{"status":"aborted","timestamp":1733374368424,"user_tz":-540,"elapsed":54,"user":{"displayName":"정인아","userId":"17927010373770908168"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1lwuRJQGHJZZSEss4WOkruBginfOpFLJB","timestamp":1697116306906}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c9069aad6eb54f43aeeed6d0040bb8f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e870a2c4df84d46813430cb014891e9","IPY_MODEL_64065a5bd3f94e46a79991b5bedb426c","IPY_MODEL_1af5101bcf6042c39259a0388e81b24f"],"layout":"IPY_MODEL_affb075472eb44049381f3f221f4a175"}},"1e870a2c4df84d46813430cb014891e9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd4cdb6dfec240ca8189880274f52b4d","placeholder":"​","style":"IPY_MODEL_bcc7e41231fd45d6a70d0e0ddba969d2","value":"tokenizer_config.json: 100%"}},"64065a5bd3f94e46a79991b5bedb426c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92756e4030de4b0d9cb365dd59e07575","max":49,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00a61b407f9d45d68607f5fb474734b7","value":49}},"1af5101bcf6042c39259a0388e81b24f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68f0bff360974fb5bdfa553327a09217","placeholder":"​","style":"IPY_MODEL_075268cc607b442c8b7bdde12e52dbcd","value":" 49.0/49.0 [00:00&lt;00:00, 1.66kB/s]"}},"affb075472eb44049381f3f221f4a175":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd4cdb6dfec240ca8189880274f52b4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcc7e41231fd45d6a70d0e0ddba969d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92756e4030de4b0d9cb365dd59e07575":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00a61b407f9d45d68607f5fb474734b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68f0bff360974fb5bdfa553327a09217":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"075268cc607b442c8b7bdde12e52dbcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91616387856341d08ada440686fff37e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e199b4de3c44ffc92e22dd46e4761a4","IPY_MODEL_bc7fdc758e1147c8b60f236c1c7c77f2","IPY_MODEL_dea19caf15dd4db6996d36213723992a"],"layout":"IPY_MODEL_f9bba456faaa47819c44da2877b71e92"}},"3e199b4de3c44ffc92e22dd46e4761a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27aeb0482542480d8725955d79fdf37a","placeholder":"​","style":"IPY_MODEL_22c67af98b804f4ab880c37b1a919e01","value":"vocab.txt: 100%"}},"bc7fdc758e1147c8b60f236c1c7c77f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d777e146e9b6451992b0368c64db8fc0","max":995526,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b203a7d0e0d48e8b7eac902397f1d26","value":995526}},"dea19caf15dd4db6996d36213723992a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62e27ba037d842e8894c8838a775dad0","placeholder":"​","style":"IPY_MODEL_5768442df44941298a7e06ca655faf05","value":" 996k/996k [00:00&lt;00:00, 4.97MB/s]"}},"f9bba456faaa47819c44da2877b71e92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27aeb0482542480d8725955d79fdf37a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22c67af98b804f4ab880c37b1a919e01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d777e146e9b6451992b0368c64db8fc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b203a7d0e0d48e8b7eac902397f1d26":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"62e27ba037d842e8894c8838a775dad0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5768442df44941298a7e06ca655faf05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1138a5eb8a0449af9bed2c61d6c58f48":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5ea3b2c94fc438e854a66be26c7bc34","IPY_MODEL_7999c51dc40d473fbb78f29ebf98bbb9","IPY_MODEL_06461d4458e34fa5baf5199c1c9686a7"],"layout":"IPY_MODEL_528631267e604db5a8f4c52c73bbffe0"}},"c5ea3b2c94fc438e854a66be26c7bc34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4023ac5dd6b4309a7eaa27b6f31ccfa","placeholder":"​","style":"IPY_MODEL_d91bbe7caa3f4749ae16b181e5e5662d","value":"tokenizer.json: 100%"}},"7999c51dc40d473fbb78f29ebf98bbb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc4cfb01a1de4200b7c9863deeab04b0","max":1961828,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7052e10d26364d2abdd302036b574026","value":1961828}},"06461d4458e34fa5baf5199c1c9686a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e780238408f8407aaae56fe960127c6d","placeholder":"​","style":"IPY_MODEL_631a8a948edf46029f928cb7e598a3f9","value":" 1.96M/1.96M [00:00&lt;00:00, 10.2MB/s]"}},"528631267e604db5a8f4c52c73bbffe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4023ac5dd6b4309a7eaa27b6f31ccfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d91bbe7caa3f4749ae16b181e5e5662d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc4cfb01a1de4200b7c9863deeab04b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7052e10d26364d2abdd302036b574026":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e780238408f8407aaae56fe960127c6d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"631a8a948edf46029f928cb7e598a3f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c69e1b0b26546f08a97d11463c2698f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_470d321d6ac944158603ada6ffda3adc","IPY_MODEL_89369c3f5e424fb1b260cddd94dabfbe","IPY_MODEL_fe42dda5bbd44dcc88d57504bd8a9f62"],"layout":"IPY_MODEL_5485a7c014d049e983ef170e749e1412"}},"470d321d6ac944158603ada6ffda3adc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e06baee970941179a3d58d4cb0fc04b","placeholder":"​","style":"IPY_MODEL_c8130a9514664c73a9548c14bcd03097","value":"config.json: 100%"}},"89369c3f5e424fb1b260cddd94dabfbe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0adb0c376b894520a6c88d89c02fd082","max":625,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37daa805e6524e8d94a8f2b5892f108e","value":625}},"fe42dda5bbd44dcc88d57504bd8a9f62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_258bc4bddc564abbaaebb35d0ef6b643","placeholder":"​","style":"IPY_MODEL_0f9beabc6b52465ca31ef439ab2f9060","value":" 625/625 [00:00&lt;00:00, 11.5kB/s]"}},"5485a7c014d049e983ef170e749e1412":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e06baee970941179a3d58d4cb0fc04b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8130a9514664c73a9548c14bcd03097":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0adb0c376b894520a6c88d89c02fd082":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37daa805e6524e8d94a8f2b5892f108e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"258bc4bddc564abbaaebb35d0ef6b643":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f9beabc6b52465ca31ef439ab2f9060":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91062fc14275403d9a9fd77afc6ba66a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dc15dfffe6834685a5e92f07aa0903b9","IPY_MODEL_0ec0e9b5a0c2420ca28a94c86cdfc212","IPY_MODEL_60b05545947e4a92bf5d9c8700d495ac"],"layout":"IPY_MODEL_2d16317d67d742078f6498821c6be6b7"}},"dc15dfffe6834685a5e92f07aa0903b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9db79d992e2a4714a009677c04a8f3f0","placeholder":"​","style":"IPY_MODEL_44c6813f75a5494d9c98de6ceffffaf5","value":"model.safetensors: 100%"}},"0ec0e9b5a0c2420ca28a94c86cdfc212":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_902575c3fe1f48d7b85588765549cff2","max":714290682,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69244a61746340ef86b31e07c77beeab","value":714290682}},"60b05545947e4a92bf5d9c8700d495ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc937bac0ce14519b870e3b978d3a563","placeholder":"​","style":"IPY_MODEL_3ee099c893d9445192f0281fef519170","value":" 714M/714M [00:05&lt;00:00, 45.3MB/s]"}},"2d16317d67d742078f6498821c6be6b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9db79d992e2a4714a009677c04a8f3f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44c6813f75a5494d9c98de6ceffffaf5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"902575c3fe1f48d7b85588765549cff2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69244a61746340ef86b31e07c77beeab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bc937bac0ce14519b870e3b978d3a563":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ee099c893d9445192f0281fef519170":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}